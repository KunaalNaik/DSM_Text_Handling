{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02_01 Reading Raw Files\n",
    "\n",
    "Python supports a number of standard and custom libraries to read files of all types into python variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#Read the file using standard python libaries\n",
    "with open(os.getcwd()+ \"/data_science.txt\", 'r') as fh:  \n",
    "    filedata = fh.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from file :  Data science is the study of data to extract meaningful insights for business. It is a multidisciplinary approach that combines principles and practices from the fields of mathematics, statistics, art\n"
     ]
    }
   ],
   "source": [
    "#Print first 200 characters in the file\n",
    "print(\"Data read from file : \", filedata[0:200] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02_02 Reading using NLTK CorpusReader\n",
    "\n",
    "Read the same text file using a Corpus Reader\n",
    "\n",
    "NLTK supports multiple CorpusReaders depending upon the type of data source. Details available in http://www.nltk.org/howto/corpus.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#install nltk from anaconda prompt using \"pip install nltk\"\n",
    "import nltk\n",
    "#Download punkt package, used part of the other commands\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science is the study of data to extract meaningful insights for business. It is a multidisciplinary approach that combines principles and practices from the fields of mathematics, statistics, artificial intelligence, and computer engineering to analyze large amounts of data. This analysis helps data scientists to ask and answer questions like what happened, why it happened, what will happen, and what can be done with the results.\n",
      "\n",
      "Data science is important because it combines tools, methods, and technology to generate meaning from data. Modern organizations are inundated with data; there is a proliferation of devices that can automatically collect and store information. Online systems and payment portals capture more data in the fields of e-commerce, medicine, finance, and every other aspect of human life. We have text, audio, video, and image data available in vast quantities.  \n"
     ]
    }
   ],
   "source": [
    "#Read the file into a corpus. The same command can read an entire directory\n",
    "corpus=PlaintextCorpusReader(os.getcwd(),\"data_science.txt\")\n",
    "\n",
    "#Print raw contents of the corpus\n",
    "print(corpus.raw())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02_03 Exploring the Corpus\n",
    "\n",
    "The corpus library supports a number of functions to extract words, paragraphs and sentences from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in this corpus :  ['data_science.txt']\n"
     ]
    }
   ],
   "source": [
    "#Extract the file IDs from the corpus\n",
    "print(\"Files in this corpus : \", corpus.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Total paragraphs in this corpus :  2\n"
     ]
    }
   ],
   "source": [
    "#Extract paragraphs from the corpus\n",
    "paragraphs=corpus.paras()\n",
    "print(\"\\n Total paragraphs in this corpus : \", len(paragraphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Total sentences in this corpus :  7\n",
      "\n",
      " The first sentence :  ['Data', 'science', 'is', 'the', 'study', 'of', 'data', 'to', 'extract', 'meaningful', 'insights', 'for', 'business', '.']\n"
     ]
    }
   ],
   "source": [
    "#Extract sentences from the corpus\n",
    "sentences=corpus.sents()\n",
    "print(\"\\n Total sentences in this corpus : \", len(sentences))\n",
    "print(\"\\n The first sentence : \", sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Words in this corpus :  ['Data', 'science', 'is', 'the', 'study', 'of', 'data', ...]\n"
     ]
    }
   ],
   "source": [
    "#Extract words from the corpus\n",
    "print(\"\\n Words in this corpus : \",corpus.words() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02_04 Analyze the Corpus\n",
    "\n",
    "The NLTK library provides a number of functions to analyze the distributions and aggregates for data in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the frequency distribution of words in the corpus\n",
    "course_freq_dist=nltk.FreqDist(corpus.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words in the corpus :  [(',', 14), ('and', 9), ('data', 7), ('.', 7), ('of', 6), ('is', 4), ('the', 4), ('to', 4), ('what', 3), ('Data', 2)]\n"
     ]
    }
   ],
   "source": [
    "#Print most commonly used words\n",
    "print(\"Top 10 words in the corpus : \", course_freq_dist.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Distribution for \"Data\" :  7\n"
     ]
    }
   ],
   "source": [
    "#find the distribution for a specific word\n",
    "print(\"\\n Distribution for \\\"Data\\\" : \",course_freq_dist.get(\"data\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
